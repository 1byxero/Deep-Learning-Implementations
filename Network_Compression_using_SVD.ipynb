{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLAssignment3part1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7GQqbs4un4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from os import getcwd\n",
        "\n",
        "model_path = getcwd()+\"assg4model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok66GfEwu9zD",
        "colab_type": "code",
        "outputId": "f77f93da-02b3-490b-f190-e9238ca650c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ]\n",
        "    )\n",
        "), batch_size=512, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root=\"./data\",\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ]\n",
        "    )\n",
        "), batch_size=512, shuffle=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1  = nn.Linear(784, 1024)  \n",
        "        self.fc2 = nn.Linear(1024, 1024)  \n",
        "        self.fc3 = nn.Linear(1024, 1024)  \n",
        "        self.fc4 = nn.Linear(1024, 1024)  \n",
        "        self.fc5 = nn.Linear(1024, 1024)  \n",
        "        self.op = nn.Linear(1024, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = F.softmax(self.op(x))\n",
        "        return x\n",
        "    \n",
        "def init_weights(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        nn.init.kaiming_normal_(layer.weight.data)\n",
        "        nn.init.zeros_(layer.bias.data)\n",
        "\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(net, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "net = Net()\n",
        "net.fc1.register_forward_hook(get_activation('fc1'))\n",
        "net.fc2.register_forward_hook(get_activation('fc2'))\n",
        "net.fc3.register_forward_hook(get_activation('fc3'))\n",
        "net.fc4.register_forward_hook(get_activation('fc4'))\n",
        "net.fc5.register_forward_hook(get_activation('fc5'))\n",
        "net.apply(init_weights)\n",
        "print(net)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (op): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ECMtk_hvLKc",
        "colab_type": "code",
        "outputId": "3fefb3de-2f0f-45b9-fefd-d00f3f6d711e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "# For sgd and adam\n",
        "epoch_count = 10\n",
        "\n",
        "accuracy_reached = False\n",
        "total_epochs = 0\n",
        "while not accuracy_reached:\n",
        "    for epoch in range(epoch_count):\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for index, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            \n",
        "            # Flatten MNIST images into a 784 long vector\n",
        "            inputs = inputs.view(inputs.shape[0], -1)\n",
        "\n",
        "            optimizer.zero_grad() \n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            if index % 100 == 99:    # print every 100 mini-batches\n",
        "                print('[%d, %5d] loss: %.6f' %\n",
        "                    (epoch + 1, index + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print(\"Done training\")\n",
        "    total_epochs+=10\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(total, accuracy))\n",
        "\n",
        "    if (accuracy>98 and total_epochs>30) or total_epochs>200:\n",
        "        accuracy_reached = True"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.747522\n",
            "[2,   100] loss: 1.587900\n",
            "[3,   100] loss: 1.500602\n",
            "[4,   100] loss: 1.487764\n",
            "[5,   100] loss: 1.482387\n",
            "[6,   100] loss: 1.478904\n",
            "[7,   100] loss: 1.475183\n",
            "[8,   100] loss: 1.473063\n",
            "[9,   100] loss: 1.472350\n",
            "[10,   100] loss: 1.470239\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 97.75 %\n",
            "[1,   100] loss: 1.469224\n",
            "[2,   100] loss: 1.468024\n",
            "[3,   100] loss: 1.467977\n",
            "[4,   100] loss: 1.468052\n",
            "[5,   100] loss: 1.466765\n",
            "[6,   100] loss: 1.466975\n",
            "[7,   100] loss: 1.466975\n",
            "[8,   100] loss: 1.467241\n",
            "[9,   100] loss: 1.466819\n",
            "[10,   100] loss: 1.468794\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 97.92 %\n",
            "[1,   100] loss: 1.466471\n",
            "[2,   100] loss: 1.466276\n",
            "[3,   100] loss: 1.465158\n",
            "[4,   100] loss: 1.465594\n",
            "[5,   100] loss: 1.465445\n",
            "[6,   100] loss: 1.465588\n",
            "[7,   100] loss: 1.465370\n",
            "[8,   100] loss: 1.465107\n",
            "[9,   100] loss: 1.467677\n",
            "[10,   100] loss: 1.466545\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 97.8 %\n",
            "[1,   100] loss: 1.465406\n",
            "[2,   100] loss: 1.465732\n",
            "[3,   100] loss: 1.466239\n",
            "[4,   100] loss: 1.464423\n",
            "[5,   100] loss: 1.464959\n",
            "[6,   100] loss: 1.464355\n",
            "[7,   100] loss: 1.464028\n",
            "[8,   100] loss: 1.464529\n",
            "[9,   100] loss: 1.464518\n",
            "[10,   100] loss: 1.464590\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 98.06 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcPVtPNb6h4g",
        "colab_type": "text"
      },
      "source": [
        "Here, I have trained a network to reach the baseline 98% Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkD1tsHtTDHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "layer_list = ['fc1','fc2','fc3','fc4', 'fc5']\n",
        "svd_over_layer_weights = []\n",
        "bias_list_over_layers = []\n",
        "for layer in layer_list:\n",
        "    svd_over_layer_weights.append(\n",
        "        torch.svd(getattr(net,layer).weight)\n",
        "    )\n",
        "    bias_list_over_layers.append(\n",
        "        getattr(net,layer).bias\n",
        "    )\n",
        "\n",
        "d_range = [10, 20, 50, 100, 200]\n",
        "w_bar_array = []\n",
        "\n",
        "for d_val in d_range:\n",
        "    w_bar_over_layers = []\n",
        "    for svd_val in svd_over_layer_weights:\n",
        "        w_bar_over_layers.append(\n",
        "            torch.matmul(\n",
        "                svd_val.U[:,:d_val], torch.matmul(\n",
        "                    torch.diag(svd_val.S)[:d_val,:d_val], svd_val.V[:,:d_val].T\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    w_bar_array.append(w_bar_over_layers)\n",
        "\n",
        "w_bar_over_layers = []\n",
        "for svd_val in svd_over_layer_weights:\n",
        "    w_bar_over_layers.append(\n",
        "    torch.matmul(svd_val.U, torch.matmul(\n",
        "            torch.diag(svd_val.S), svd_val.V.T\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "w_bar_array.append(\n",
        "    w_bar_over_layers\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_xT2txQ-IEn",
        "colab_type": "code",
        "outputId": "f4cf16ab-6179-48ae-a87d-6118e0b0a6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "d_range += ['D_Full']\n",
        "\n",
        "accuracy_over_d_parameter = []\n",
        "\n",
        "for index, w_bar in enumerate(w_bar_array):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net2 = Net()\n",
        "\n",
        "\n",
        "    net2.fc1.weight.data = w_bar[0]\n",
        "    net2.fc2.weight.data = w_bar[1]\n",
        "    net2.fc3.weight.data = w_bar[2]\n",
        "    net2.fc4.weight.data = w_bar[3]\n",
        "    net2.fc5.weight.data = w_bar[4]\n",
        "    net2.fc1.bias.data = bias_list_over_layers[0]\n",
        "    net2.fc2.bias.data = bias_list_over_layers[1]\n",
        "    net2.fc3.bias.data = bias_list_over_layers[2]\n",
        "    net2.fc4.bias.data = bias_list_over_layers[3]\n",
        "    net2.fc5.bias.data = bias_list_over_layers[4]\n",
        "    net2.op.weight = net.op.weight\n",
        "    net2.op.bias = net.op.bias\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            outputs = net2(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the {} test images with D Value:{} is {} %'.format(total, d_range[index], accuracy))\n",
        "    accuracy_over_d_parameter.append(accuracy)\n",
        "\n",
        "plt.plot(d_range, accuracy_over_d_parameter)\n",
        "plt.xlabel('D Value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images with D Value:10 is 25.72 %\n",
            "Accuracy of the network on the 10000 test images with D Value:20 is 37.23 %\n",
            "Accuracy of the network on the 10000 test images with D Value:50 is 60.46 %\n",
            "Accuracy of the network on the 10000 test images with D Value:100 is 73.36 %\n",
            "Accuracy of the network on the 10000 test images with D Value:200 is 91.74 %\n",
            "Accuracy of the network on the 10000 test images with D Value:D_Full is 98.06 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXRU9f3/8eebsO9LFtnCIjsoWwTc\nUdRqtdW2at0AFcRWa61+2+qv3652Odq6VKtVEVCkiFqXurRVEMWdSFhE1gCBIAgkbGEn2/v3x1zy\nTWmAJGTmJjOvxzk5M/cz92be92SSV+72vubuiIiIANQLuwAREak9FAoiIlJGoSAiImUUCiIiUkah\nICIiZeqHXcDxSE5O9q5du4ZdhohInTJ//vyt7p5S0Wt1OhS6du1KVlZW2GWIiNQpZpZ7pNeitvvI\nzKaYWZ6ZLSk31tbMZpnZquCxTTBuZvaIma02s8VmNiRadYmIyJFF85jCM8CFh43dDcx2957A7GAa\n4CKgZ/A1AXg8inWJiMgRRC0U3P0DYPthw5cCU4PnU4HLyo0/6xFzgdZm1j5atYmISMViffZRmrtv\nCp5vBtKC5x2BL8vNtyEY+y9mNsHMsswsKz8/P3qViogkoNBOSfVI06UqN15y94nunuHuGSkpFR48\nFxGRaop1KGw5tFsoeMwLxjcCncvN1ykYExGRGIp1KLwOjA2ejwVeKzc+JjgLaQRQUG43k4iIxEg0\nT0mdAXwK9DazDWY2DrgXON/MVgHnBdMA/wJygNXAU8At0apLRKQu27BjH9Mzc8nJ3xOV7x+1i9fc\n/eojvDSqgnkduDVatYiI1FUHi0v4bO123l+Zz5zsfFbnRcLg5xf3pXtK8xp/vzp9RbOISDxav20f\nc7LzeH9lPp+s2cb+ohIaJtVjWLe2XHVKZ0b2TuHEKAQCKBREREJ3oKiEuTnbmLMynw+y88nZuheA\n9LZNuSKjE2f3SuHUE9vRtGH0/2QrFEREYszdWbt1L+9n5zNnZT5zc7ZxsLiURvXrMaJ7O0af2oWz\ne6XQLbkZZhbT2hQKIiIxsK+wmE/XbCsLgvXb9wHQPbkZVw9LZ2TvFEZ0b0fjBkmh1qlQEBGJAndn\nTf4e5qzM5/3sfDJztlNYUkqTBkmcdmI7xp/ZjZG9Uklv1zTsUv+DQkFEpIbsOVjMJ6u3Mic7n/dX\n5rNx534AeqQ2Z8ypXTi7dwqndG0b+tbA0SgURESqyd1ZuWV35HTRlflk5W6nqMRp1jCJ03okc8s5\nJ3J2rxQ6taldWwNHo1AQEamCXQeK+HjV1rLdQpt3HQCgzwktuPGMbpzdK4WMLm1pWL9u3u1YoSAi\nchTuzrJNuyIhsDKf+et3UFLqtGhUnzN6JjOydwpn9UqhfasmYZdaIxQKIiKHKdhXxIer88u2BvJ3\nHwSgf4eW3HxWd0b2TmVwemsaJNXNrYGjUSiISMIrLXWWfFVQ1kpi4fodlDq0atKAM3smc3avFM7u\nlUJqy8Zhlxp1CgURSUjb9xby4ar8squIt+0tBODkTq34wTk9OLt3KgM7taJ+HG4NHI1CQUQSQkmp\ns3jDTuYEWwOLN+zEHdo0bcBZvVIY2TuFM3umkNy8UdilhkqhICJxK3/3wbKtgQ9X5bNjXxFmMKhz\na24f1ZORvVM5qWMrkurFtpVEbaZQEJG4UVxSyqIvd5a1kvhiYwEAyc0bck6fVEb2TuXMHsm0adYw\n5EprL4WCiNRpW/cc5N0Vebyfnc+H2fnsOlBMUj1jSHprfnxBL0b2TqVf+5bU09ZApSgURKTOemvJ\nZu58cRH7CktIbdGICwecwNm9UjmjRzKtmjYIu7w6SaEgInWOu/Pou6t5YFY2Azu35g/fGkC/9i1j\n3mY6HoVyrpWZ3W5mS8xsqZn9KBhra2azzGxV8NgmjNpEpHbbX1jCbTMW8sCsbL41uCMvTBhB/w6t\nFAg1JOahYGYDgJuAYcBA4BIz6wHcDcx2957A7GBaRKTMpoL9XPnkp/zzi03cfVEfHrxyYK3uOFoX\nhbH7qC+Q6e77AMzsfeDbwKXAyGCeqcAc4K4Q6hORWmjh+h1MmDaffQeLmTQmg1F908IuKS6Fsfto\nCXCmmbUzs6bA14HOQJq7bwrm2QxU+BM3swlmlmVmWfn5+bGpWERC9erCDXx34lyaNEji1VtPVyBE\nUcy3FNx9uZndB8wE9gKLgJLD5nEz8yMsPxGYCJCRkVHhPCISH0pKnT++vYIn389hRPe2PH7tUF1j\nEGWhHGh298nuPtTdzwJ2ANnAFjNrDxA85oVRm4jUDrsPFHHTs1k8+X4O141IZ9q44QqEGAjllFQz\nS3X3PDNLJ3I8YQTQDRgL3Bs8vhZGbSISvtxtexk/NYucrXv57aX9GX1q17BLShhhXafwspm1A4qA\nW919p5ndC7xoZuOAXODKkGoTkRB9smYrt0xfgDtMu3EYp/VIDrukhBJKKLj7mRWMbQNGhVCOiNQS\n0+bm8pvXl9I1uRmTx2bQpV2zsEtKOLqiWURCV1RSyj1vLGPa3FzO7ZPKw1cNokVjtakIg0JBREK1\nY28ht0xfwKc527j5rO789MI+amUdIoWCiIRm1ZbdjJuaxeaCAzxwxUC+M7RT2CUlPIWCiITi3RVb\n+OGMRTRukMTzN49gSLrandUGCgURiSl3Z+IHOdz71gr6d2jJxNEZdGjdJOyyJKBQEJGYOVBUws9e\n+YJXFm7k4pPbc//lA2nSUA3tahOFgojERN6uA0yYNp9FX+7kzvN7cdu5PdTuuhZSKIhI1H2xoYCb\nns2iYH8RT1w3hAsHtA+7JDkChYKIRNUbn3/FT176nHbNGvHS90+lf4dWYZckR6FQEJGoKC11/vxO\nNo+8u5qMLm14YvRQkps3CrssOQaFgojUuL0Hi7nzxUW8vXQLV2Z04reXDaBRfR1QrgsUCiJSozbs\n2Mf4qVlkb9nNLy7px42nd9UB5TpEoSAiNWbeuu18b9p8CktKefqGYZzdKyXskqSKFAoiUiNemLee\nn/9jCZ3aNGXS2AxOTGkedklSDQoFETkuxSWl/OFfK5jy8VrO7JnMo1cPoVVTdTitqxQKIlJtBfuL\nuG3GQj7IzueG07vyv1/vS/2kUO7yKzVEoSAi1ZKTv4fxz2bx5fZ93Pvtk7hqWHrYJUkNUCiISJV9\nkJ3PD55bQP2kevxt3HCGd28XdklSQ0LZzjOzO8xsqZktMbMZZtbYzLqZWaaZrTazF8ysYRi1iciR\nuTtTPlrL9U9/RofWTXjt1tMVCHEm5qFgZh2BHwIZ7j4ASAKuAu4DHnL3HsAOYFysaxORIyssLuXu\nl7/gnjeXMapvGi9//zQ6t20adllSw8I6IlQfaGJm9YGmwCbgXOCl4PWpwGUh1SYih9m65yDXTprL\nC1lf8oNzevDkdUNp1kh7n+NRzH+q7r7RzO4H1gP7gZnAfGCnuxcHs20AOsa6NhH5b8s37WL81Cy2\n7jnIw1cN4tJB+tWMZ2HsPmoDXAp0AzoAzYALq7D8BDPLMrOs/Pz8KFUpIgBvL93Mdx7/hOLSUl68\n+VQFQgIIY/fRecBad8939yLgFeB0oHWwOwmgE7CxooXdfaK7Z7h7RkqKLqEXiQZ35y+zV3HztPn0\nTGvB6z84g4GdW4ddlsRAGKGwHhhhZk0t0iVrFLAMeA+4PJhnLPBaCLWJJLz9hSX88PlFPDArm8sG\ndeCFCSNIa9k47LIkRsI4ppBpZi8BC4BiYCEwEfgn8LyZ/S4Ymxzr2kQS3eaCA9z0bBZLvirgrgv7\n8L2zu6vDaYIJ5fQBd/8V8KvDhnOAYSGUIyLAwvU7mDBtPvsOFvPU6AzO65cWdkkSAp1TJiK8unAD\nd738BWktG/G3cafT+4QWYZckIVEoiCSwklLnT2+v5In31zC8W1sev24obZupmUAiUyiIJKjdB4r4\n0fOLmL0ij2uGp/Prb/SnYX11OE10CgWRBLR+2z7GPzuPNfl7+e2l/Rl9atewS5JaQqEgkmA+WbOV\nW6YvwB2evXEYp/dIDrskqUUUCiIJ5G9zc/n160vp0q4pk8eeQtfkZmGXJLWMQkEkARSVlHLPG8uY\nNjeXc3qn8PDVg2nZWLfMlP+mUBCJczv2FnLrcwv4ZM02JpzVnbsu7ENSPV2QJhVTKIjEsVVbdjP+\n2Sw27TzA/VcM5PKhncIuSWo5hYJInHpvRR63zVhI4wZJzJgwgqFd2oRdktQBCgWROOPuTPwgh3vf\nWkG/9i15akwGHVo3CbssqSMUCiJx5EBRCT975QteWbiRi09qz5+uOJmmDfVrLpWnT4tInJifu51f\nvraUpV/t4o7zevHDUT3U4VSqTKEgUsdtKtjPvf9ewWuLviKtZSOeHD2Ur/U/IeyypI5SKIjUUQeK\nSnjqgxz+OmcNJe784JwefH/kiTRrpF9rqT59ekTqGHfnrSWb+f2/lrNhx34uGnACP/t6Xzq3bRp2\naRIHFAoidcjyTbv4zRtLmZuznT4ntOC58cM5Tb2LpAYpFETqgO17C3lg5kpmfLaeVk0a8NvLBnD1\nKZ2pn6RW11KzFAoitVhRSSl/m5vLQ7Oy2VtYwphTu/Kj83rSuqluhCPREfNQMLPewAvlhroDvwSe\nDca7AuuAK919R6zrE6ktPsjO5543l7E6bw9n9kzml5f0o2eabpMp0RXzUHD3lcAgADNLAjYCrwJ3\nA7Pd/V4zuzuYvivW9YmEbd3Wvfzun8t5Z/kWurRrylNjMjivb6quOZCYCHv30ShgjbvnmtmlwMhg\nfCowB4WCJJA9B4v5y7urmPLRWhom1ePui/pww+ldaVQ/KezSJIGEHQpXATOC52nuvil4vhlIq2gB\nM5sATABIT0+PeoEi0VZa6ry8YAN/fHsl+bsPcvnQTvz0a71Jbdk47NIkAYUWCmbWEPgm8P8Of83d\n3cy8ouXcfSIwESAjI6PCeUTqivm5O/jNG0tZvKGAwemtmTQmg4GdW4ddliSwY4aCmd0G/C0KB30v\nAha4+5ZgeouZtXf3TWbWHsir4fcTqTU2FxzgvrdW8OrCjaS1bMRD3x3IpQM7Uk83v5GQVWZLIQ2Y\nZ2YLgCnA2+5eE/+hX83/7ToCeB0YC9wbPL5WA+8hUqscKCph0oc5PPaeWlNI7WSV+ftukdMeLgBu\nADKAF4HJ7r6mWm9q1gxYD3R394JgrF3wfdOBXCKnpG4/2vfJyMjwrKys6pQgElNqTSG1iZnNd/eM\nil6r1L8nwT7+zUQOABcDbYCXzGyWu/+0qgW5+16g3WFj24icjSQSV5Zv2sU9byzj05xtak0htV5l\njincDowBtgKTgJ+4e5GZ1QNWAVUOBZFEsH1vIQ/OWslzmetpqdYUUkdUZkuhLfBtd88tP+jupWZ2\nSXTKEqm71JpC6rLKhMK/gbJ9+2bWEujr7pnuvjxqlYnUQR+uyueeN5axKm8PZ/RI5pff6EcvtaaQ\nOqQyofA4MKTc9J4KxkQSmlpTSLyoTChY+VNQg91GOn9OhEhrikffXc2Uj9bSIMm468I+3HiGWlNI\n3VWZP+45ZvZDIlsHALcAOdErSaT2U2sKiVeVCYXvAY8APwccmE3Qe0gkES1Yv4PfvL6UzzcUMKhz\na54ak8EgtaaQOHHMUHD3PCKN60QSmlpTSCKozHUKjYFxQH+gbNvY3W+MYl0itcaBohImf7SWx95b\nTXGpWlNIfKvMp3oasAL4GnAPcC2gU1El7rk7by/dzO/+GWlNcWH/SGuK9HZqTSHxqzKh0MPdrzCz\nS919qpk9B3wY7cJEwrRic6Q1xSdrttE7Ta0pJHFUJhSKgsedZjaASP+j1OiVJBKeHXsLeXBWNtMz\ncyOtKS7tz9XD0tWaQhJGZUJhopm1IXL20etAc+AXUa1KJMaKS0qZnrmeB2dls+dgsVpTSMI6aigE\nTe92BTfY+QDoHpOqRGLoo1VbuefNpWRvUWsKkaOGQnD18k+J3OdAJK7kbou0ppi1bAvpbZsycfRQ\nzu+XptYUktAqs/voHTP7MfACsPfQ4LFugCNSW5VvTVE/yfjphb0Zd0Y3taYQoXKh8N3g8dZyY452\nJUkdU1rqvLJwI/e9tYL83Qf5zpBO/PTC3qSpNYVImcpc0dwtFoWIRNOC9Tv4zRvL+PzLnWpNIXIU\nlbmieUxF4+7+bHXf1MxaE7mL2wAiWx03AiuJ7KLqCqwjco/mHdV9DxGALbsOcN+/V/CKWlOIVEpl\ndh+dUu55YyL3UV4AVDsUgIeBt9z9cjNrCDQFfgbMdvd7zexu4G7gruN4D0lw0zNz+f0/l1Nc6tx6\nzoncMrKHWlOIHENldh/dVn46+C//+eq+oZm1As4Crg++fyFQaGaXAiOD2aYCc1AoSDVNm5vLL/6x\nhLN6pfC7SweoNYVIJVXnMs29wPEcZ+gG5ANPm9lCM5tkZs2ANHffFMyzGUiraGEzm2BmWWaWlZ+f\nfxxlSLx6af4GfvGPJZzXN5VJYzIUCCJVUJljCm8Q2e8PkRDpx/Fdt1CfyK08b3P3TDN7mMiuojLu\n7mbmFS3s7hOBiQAZGRkVziOJ643Pv+KnL33OmT2TefSaITSsr/YUIlVRmR2s95d7XgzkuvuG43jP\nDcAGd88Mpl8iEgpbzKy9u28ys/ZA3nG8hySgWcu2cMcLi8jo0pYnRw+lcQNddyBSVZX5N2o9kOnu\n77v7x8A2M+ta3Td0983Al2bWOxgaBSwj0ldpbDA2Fnituu8hieeD7Hxunb6A/h1bMfn6DJo21AFl\nkeqozG/O34HTyk2XBGOnVDx7pdwGTA/OPMoBbiASUC+a2TggF7jyOL6/JJDMnG1MmJbFianNmXrD\nKbRo3CDskkTqrMqEQv3gDCEgcrZQ8Me82tx9EZBRwUujjuf7SuJZuH4HNz4zj46tmzBt3DB1NRU5\nTpXZfZRvZt88NBGcOro1eiWJVM7SrwoYO+Uzkls04rmbRpDcvFHYJYnUeZXZUvgekV09jwbTG4AK\nr3IWiZVVW3YzevJnNG9Un+njh6t/kUgNqczFa2uAEWbWPJjeE/WqRI5i3da9XDspk6R6xvSbRtCp\nja5DEKkpx9x9ZGZ/MLPW7r7H3feYWRsz+10sihM53IYd+7h2UiZFJaVMHz+cbsnNwi5JJK5U5pjC\nRe6+89BE0KTu69ErSaRiW3Yd4NpJmew6UMS0ccN1dzSRKKhMKCSZWdkRPDNrAuiInsTUtj0HuXZS\nJlt3H2TqjcMY0LFV2CWJxKXKHGieDsw2s6cBI9LIbmo0ixIpr2BfEaMnf8aX2/cx9cZhDElvE3ZJ\nInGrMgea7zOzz4HziPRAehvoEu3CRCBy68yxT3/G6rw9PDU2gxHd24Vdkkhcq2y3sC1EAuEK4Fxg\nedQqEgnsLyzhxmfm8cXGAh69ZjBn90oJuySRuHfELQUz6wVcHXxtJXJXNHP3c2JUmySwg8UlTJiW\nxbx123n4qsFc0P+EsEsSSQhH2320AvgQuMTdVwOY2R0xqUoSWlFJKbdOX8iHq7byx8tP5psDO4Rd\nkkjCONruo28Dm4D3zOwpMxtF5ECzSNSUlDp3vLCId5Zv4beX9ufKjM5hlySSUI4YCu7+D3e/CugD\nvAf8CEg1s8fN7IJYFSiJo7TUuevlxby5eBM/+3ofRp/aNeySRBLOMQ80u/ted3/O3b8BdAIWonsn\nSw1zd375+hJemr+BH53XkwlnnRh2SSIJqUr3KnT3He4+0d3V4lpqjLvzh38t529z13Pz2d25fVTP\nsEsSSVi6ga2E7qF3VvHUh2sZe2oX7r6wD2Y6dCUSFoWChOrxOWt4ZPYqrhjaiV99o78CQSRkCgUJ\nzTMfr+W+t1bwjYEduPc7J1OvngJBJGyh3N3czNYBu4nc77nY3TPMrC2RC+S6AuuAK4OOrBKHXpi3\nnl+/sYzz+6Xx4JUDSVIgiNQKYW4pnOPug9z90L2a7wZmu3tPYHYwLXHotUUbufuVLzirVwqPXjOY\nBknaYBWpLWrTb+Ol/F/31anAZSHWIlHy1pLN3Pni5wzr2pYnrxtKo/pJYZckIuWEFQoOzDSz+WY2\nIRhLc/dNwfPNQFo4pUm0vLcyj9tmLODkTq2YfP0pNGmoQBCpbUI5pgCc4e4bzSwVmGVmK8q/6O5u\nZl7RgkGITABIT0+PfqVSIz5Zs5XvTZtPr7QWPHPDMJo3CuujJyJHE8qWgrtvDB7zgFeBYcAWM2sP\nEDzmHWHZie6e4e4ZKSlqpVwXzM/dzvipWaS3bcq0ccNp1aRB2CWJyBHEPBTMrJmZtTj0HLgAWAK8\nDowNZhsLvBbr2qTmfbGhgOunzCO1RSOmjx9O22YNwy5JRI4ijG34NODV4CKl+sBz7v6Wmc0DXjSz\ncUAucGUItUkNWrl5N6OnZNKySQOm3zSC1JaNwy5JRI4h5qHg7jnAwArGtwHqqRQncvL3cO2kTBrV\nr8dzNw2nY+smYZckIpVQm05JlTjx5fZ9XDspE3dn+vjhdGnXLOySRKSSdAqI1KjNBQe4ZtJc9hWW\nMOOmEfRIbRF2SSJSBdpSkBqTv/sg10yay469RUy9cRj9OrQMuyQRqSKFgtSInfsKGT05k6927mfK\n9acwqHPrsEsSkWrQ7iM5brsOFDFmymfkbN3LlLGnMKxb27BLEpFq0paCHJd9hcXc+PQ8ln21i8ev\nHcIZPZPDLklEjoNCQartQFEJNz2bxYL1O3j4qsGM6qt2VSJ1nXYfSbUUFpdyy/QFfLx6Gw9cMZCL\nT24fdkkiUgO0pSBVVlxSyu3PL+TdFXn8/lsD+M7QTmGXJCI1RKEgVVJa6vzkpcX8e8lmfn5xX64d\n3iXskkSkBikUpNLcnf/9xxJeXbiRH1/Qi/Fndg+7JBGpYQoFqRR35543lzHjs/XcMvJEfnBuz7BL\nEpEoUChIpdw/cyVPf7yOG07vyk++1jvsckQkShQKckyPvruKx95bw9XDOvPLS/oRtD0XkTikUJCj\nmvzRWu6fmc23Bnfkd5edpEAQiXMKBTmi6Zm5/PbNZVw04AT+dPnJJNVTIIjEO4WCVOiVBRv4+T+W\ncE7vFB6+ajD1k/RREUkE+k2X//LPxZv48d8/59Tu7Xj8uqE0rK+PiUii0G+7/IfZy7dw+/MLGZLe\nhqfGZNC4QVLYJYlIDIUWCmaWZGYLzezNYLqbmWWa2Woze8HMGoZVW6L6aNVWvj99Af06tGTKDafQ\nrJFaY4kkmjC3FG4Hlpebvg94yN17ADuAcaFUlaDmrdvOTc9m0T25GVNvGEbLxg3CLklEQhBKKJhZ\nJ+BiYFIwbcC5wEvBLFOBy8KoLRF9/uVObnh6Hu1bN2bauOG0aaaNNJFEFdaWwp+BnwKlwXQ7YKe7\nFwfTG4COFS1oZhPMLMvMsvLz86NfaZxbvmkXY6Z8RptmDZg+fjgpLRqFXZKIhCjmoWBmlwB57j6/\nOsu7+0R3z3D3jJSUlBquLrGsztvDdZMyadowiefGj6B9qyZhlyQiIQvjSOLpwDfN7OtAY6Al8DDQ\n2szqB1sLnYCNIdSWMHK37eXaSXMxM6aPH07ntk3DLklEaoGYbym4+/9z907u3hW4CnjX3a8F3gMu\nD2YbC7wW69oSxVc793PNU5kcLC5l+vjhdE9pHnZJIlJL1KbrFO4C7jSz1USOMUwOuZ64lLf7ANdO\nymTX/iKm3Tic3ie0CLskEalFQj0R3d3nAHOC5znAsDDriXfb9xZy3aRMtuw6wLRxwzipU6uwSxKR\nWqY2bSlIFBXsL2LMlExyt+1j0pgMhnZpG3ZJIlIL6ZLVOHewuITnMtfz2HtrKNhfyMQxGZzWIzns\nskSkllIoxKmiklJemr+Bv8xexVcFBxjerS13XTSUIeltwi5NRGoxhUKcKSl1Xlu0kT+/s4r12/cx\nqHNr/nTFQE47sZ1ukCMix6RQiBOlpc5bSzfz4KxsVuftoW/7lkwem8G5fVIVBiJSaQqFOs7deXdF\nHg/MzGbZpl2cmNKMx64ZwkUDTqCe7pQmIlWkUKij3J1P1mzj/pkrWbh+J+ltm/LglQO5dFBH3TZT\nRKpNoVAHZa3bzv0zVzI3ZzvtWzXmD986iSsyOtFAt8wUkeOkUKhDvthQwAOzVjJnZT7JzRvxq2/0\n4+ph6bo7mojUGIVCHbBy824enLWSt5duoVWTBtx1YR/GntaFpg314xORmqW/KrXY2q17+fM72bz+\n+Vc0a1ifH53XkxvP6Ka7oolI1CgUaqENO/bxyOxVvLxgIw2SjJvPOpGbz+quO6KJSNQpFGqRLbsO\n8Nh7q5nx2XoMY8ypXfj+yBNJbdE47NJEJEEoFGqBbXsO8sT7a3j201xKSp0rMjpz27k96NBad0IT\nkdhSKISoYH8Rkz7MYcpHa9lfVMJlgzty+6iedGnXLOzSRCRBKRRCsPdgMU9/vJaJH+Sw60AxF5/U\nnjvO70mPVN3wRkTCpVCIoQNFJfxtbi5/nbOG7XsLOa9vKnec34v+HXSzGxGpHRQKMVBYXMoL89bz\nl3dXk7f7IGf2TObO83sxWG2sRaSWiXkomFlj4AOgUfD+L7n7r8ysG/A8kfszzwdGu3thrOurScUl\npbyycCMPv7OKjTv3k9GlDY9cPZgR3duFXZqISIXC2FI4CJzr7nvMrAHwkZn9G7gTeMjdnzezJ4Bx\nwOMh1HfcSkudN7/YxJ9nZZOzdS8nd2rFH759Emf1TFYbaxGp1WIeCu7uwJ5gskHw5cC5wDXB+FTg\n19SxUHB3Zi7bwoMzs1m5ZTe901rw5OihXNAvTWEgInVCKMcUzCyJyC6iHsBjwBpgp7sXB7NsADoe\nYdkJwASA9PT06BdbCe7OB6u28sDMlSzeUED35GY8cvVgLjmpve5pICJ1Siih4O4lwCAzaw28CvSp\nwrITgYkAGRkZHp0KK29uzjYemLmSeet20LF1E/54+cl8e3BH6quNtYjUQaGefeTuO83sPeBUoLWZ\n1Q+2FjoBG8Os7VgWrt/Bg7Oy+XDVVtJaNuK3lw3guxmdaVhfYSAidVcYZx+lAEVBIDQBzgfuA94D\nLidyBtJY4LVY11YZS78q4KFZ2byzPI+2zRry84v7ct2ILrqngYjEhTC2FNoDU4PjCvWAF939TTNb\nBjxvZr8DFgKTQ6jtiFbn7Yv6z0IAAAbGSURBVOahd1bxz8WbaNm4Pj/5Wm/GntaV5o10qYeIxI8w\nzj5aDAyuYDwHGBbreo5l/bZ9/Hl2Nv9YuJEmDZK47dwejD+zO62a6J4GIhJ/9G/uEWwq2M9f3l3N\ni/O+JKmeMf7M7tx8VnfaNW8UdmkiIlGjUDhM/u6D/HXOaqZnrsfduWZ4Oree04O0lrqngYjEP4VC\nYOe+Qp78IIdnPl5HYUkplw/pxG2jetCpTdOwSxMRiZmED4XdB4qY/NFaJn+4lj2FxXxzYAduH9WT\n7inNwy5NRCTmEjYU9hUW8+ynuTzx/hp27ivia/3TuPP83vQ+Qfc0EJHElZCh8Obir/j168vYuucg\nI3un8D/n9+akTrqngYhIQoZC4/pJ9EhtxhPXDSGja9uwyxERqTUSMhRG9U1lVN9UdS4VETlMQoaC\nwkBEpGLq3iYiImUUCiIiUkahICIiZRQKIiJSRqEgIiJlFAoiIlJGoSAiImXM3cOuodrMLB/Irebi\nycDWGiynLtA6Jwatc2I4nnXu4u4pFb1Qp0PheJhZlrtnhF1HLGmdE4PWOTFEa521+0hERMooFERE\npEwih8LEsAsIgdY5MWidE0NU1jlhjymIiMh/S+QtBREROYxCQUREyiREKJjZFDPLM7Ml5cbamtks\nM1sVPLYJs8aaZmadzew9M1tmZkvN7PZgPN7Xe52ZfWFmi8wsKxiLq3WuyufZIh4xs9VmttjMhoRX\nefVU9bMcD+scpoQIBeAZ4MLDxu4GZrt7T2B2MB1PioH/cfd+wAjgVjPrR/yvN8A57j6o3Dnc8bbO\nz1D5z/NFQM/gawLweIxqrElV/SzXmXU2s5LgH5ilZva5mf2PmR3x77KZjTSzgmCZRWb2zjG+f9dD\n/zwEy755zKLcPSG+gK7AknLTK4H2wfP2wMqwa4zy+r8GnB/v6w2sA5IPG4u7da7s5xl4Eri6ovnq\n6texPst1aZ2BPeWepwLvAL85yvwjgTer8zmp7LKJsqVQkTR33xQ83wykhVlMNJlZV2AwkEn8r7cD\nM81svplNCMbifZ3hyOvYEfiy3HwbgrE6qZKf5Tq5zu6eR2TL5gdWxXsGm9kzZnZ5uek91a0jIe/R\nfDh3dzOLy3Nzzaw58DLwI3ffVf6zFqfrfYa7bzSzVGCWma0o/2KcrvN/iNd1TITPsrvnmFkSka2G\nLUeY7UwzWxQ8/7u7/74ma0jkUNhiZu3dfZOZtQfywi6opplZAyK/RNPd/ZVgOK7X2903Bo95ZvYq\nMIw4X+fAkdZxI9C53HydgrE6pYqf5bhY56P40N0vidY3T+TdR68DY4PnY4nsp4wbwebnZGC5uz9Y\n7qW4XW8za2ZmLQ49By4AlhDH61zOkdbxdWBMcEbOCKCg3C6XOqEan+U6u85m1h0ooer/uBQT/D0P\nDlQ3rHYRYR9oidHBnBnAJqCIyP7FcUA7ImcsrCJycKdt2HXW8DqfQWT/+mJgUfD19Xheb6A78Hnw\ntRT432A8rta5Kp9nwIDHgDXAF0BG2PVXY32r9FmuS+vMfx5oTgFmUo0DzcDPgfuC55dF/rRX70Cz\n2lyIiITEzEqIBFcDIv/tTwMedPfSI8w/EvixH7b7yMzSiGwpNQHeAm519+bBgfk33X3AkZb9r/dQ\nKIiIyCGJfExBREQOk8hnH4mI1Epm9jXgvsOG17r7t6L+3tp9JCIih2j3kYiIlFEoiIhIGYWCSDmV\n7VppZjlm1vuwsT+b2V1H+d5lHStFaiuFgsh/2u+Rttv9iXTivAj4VQXzPQ9cdWgiCI7Lg3GROkuh\nIHIEfvSulTOA75abPgvIdffcYIvgQzNbEHyddvj3NrPrzezRctNvBhcXYWYXmNmnwbJ/DxrBicSE\nQkHkKNw9BzjUtbL8+BdAqZkNDIauIhIUEOlbc767DyESHI9U9v3MLJlIy4LzguWzgDuPayVEqkDX\nKYhU3wzgKjNbSqTfzKHdTA2AR81sEJHmZr2q8D1HAP2Aj4ONk4bApzVWscgxKBREjuIYXSufJ9LA\n7H1gsbsf6n9/B5Fe+AOJbI0fqGDZsq6WgcaH3hKY5e5XH3/1IlWn3UciR2BmKcATwKNewVWe7r4G\n2Arcy//tOgJoBWwKmpqNJrL76XDrgEFmVs/MOhO57wPAXOB0M+sR1NDMzKqypSFyXBQKIv+pyaFT\nUom0Y54J/OYo888A+gCvlBv7KzDWzD4PXttbwXIfA2uBZUSOOSwAcPd84HpghpktJrLrqM/xrJBI\nVajNhYiIlNGWgoiIlFEoiIhIGYWCiIiUUSiIiEgZhYKIiJRRKIiISBmFgoiIlPn/jAncnh5CBy8A\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVMXP_4I6x3R",
        "colab_type": "text"
      },
      "source": [
        "Here, I have initialized the networks with doing svd over the weights.\n",
        "\n",
        "We can see that as we increase D, the network starts to perform better and better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wekApKvAudVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class USVLayer(torch.nn.Module):\n",
        "   \n",
        "    def __init__(self, in_feat, out_feat, D_val):\n",
        "        super(USVLayer, self).__init__()\n",
        "        self.U_matrix = nn.Parameter(torch.Tensor(out_feat, in_feat)[:,:D_val])\n",
        "        self.V_matrix = nn.Parameter(\n",
        "            torch.Tensor(out_feat, in_feat)[:,:D_val]\n",
        "        )\n",
        "        self.bias = nn.Parameter(\n",
        "            torch.Tensor(out_feat)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "\n",
        "        op1 = self.U_matrix.matmul(\n",
        "            self.V_matrix\n",
        "        )\n",
        "        op2 = input.matmul(op1.T)\n",
        "        return op2 + self.bias\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItJ2VTyX688p",
        "colab_type": "text"
      },
      "source": [
        "Here, I have created my custom layer which has U and V_bar matrix as its parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3aFjGR9Azb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_val = 20\n",
        "\n",
        "class NetCool(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NetCool, self).__init__()\n",
        "        self.fc1  = USVLayer(784, 1024, D_val)  \n",
        "        self.fc2 = USVLayer(1024, 1024, D_val)  \n",
        "        self.fc3 = USVLayer(1024, 1024, D_val)  \n",
        "        self.fc4 = USVLayer(1024, 1024, D_val)  \n",
        "        self.fc5 = USVLayer(1024, 1024, D_val)  \n",
        "        self.op = nn.Linear(1024, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = F.softmax(self.op(x))\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV_rUcctBNtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For sgd and adam\n",
        "netcool = NetCool()\n",
        "\n",
        "for index, layer in enumerate(layer_list):\n",
        "    obj = getattr(netcool, layer)\n",
        "    obj.U_matrix.data = svd_over_layer_weights[index].U[:,:D_val]\n",
        "    obj.V_matrix.data = torch.diag(\n",
        "        svd_over_layer_weights[index].S)[:D_val,:D_val].matmul(\n",
        "            svd_over_layer_weights[index].V[:,:D_val].T\n",
        "        )\n",
        "    obj.bias.data = bias_list_over_layers[index]\n",
        "\n",
        "netcool.op.weight = net.op.weight\n",
        "netcool.op.bias = net.op.bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJq8ba587SIt",
        "colab_type": "text"
      },
      "source": [
        "Here, I have created the network and initialized it with U and V matrix values with SVDed weights as was instructed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTaelRwWdH5b",
        "colab_type": "code",
        "outputId": "f149ac85-897e-453e-eda8-831d75165ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch_count = 10\n",
        "learning_rate2 = 1e-4\n",
        "optimizer2 = optim.Adam(net.parameters(), lr=learning_rate2)\n",
        "\n",
        "accuracy_reached = False\n",
        "total_epochs = 0\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "accuracy_on_finetuning = []\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        outputs = netcool(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the network before finetuning on the {} test images: {} %'.format(total, accuracy))\n",
        "accuracy_on_finetuning.append(accuracy)\n",
        "\n",
        "while not accuracy_reached:\n",
        "    for epoch in range(epoch_count):\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for index, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            \n",
        "            # Flatten MNIST images into a 784 long vector\n",
        "            inputs = inputs.view(inputs.shape[0], -1)\n",
        "\n",
        "            optimizer2.zero_grad() \n",
        "\n",
        "            outputs = netcool(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer2.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            if index % 100 == 99:    # print every 100 mini-batches\n",
        "                print('[%d, %5d] loss: %.6f' %\n",
        "                    (epoch + 1, index + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "    print(\"Done training\")\n",
        "    total_epochs+=10\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            outputs = netcool(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(total, accuracy))\n",
        "    if accuracy>90 or total_epochs == 200:\n",
        "        accuracy_reached = True\n",
        "    accuracy_on_finetuning.append(accuracy)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network before finetuning on the 10000 test images: 37.23 %\n",
            "[1,   100] loss: 2.189584\n",
            "[2,   100] loss: 2.144605\n",
            "[3,   100] loss: 2.110760\n",
            "[4,   100] loss: 2.085255\n",
            "[5,   100] loss: 2.065560\n",
            "[6,   100] loss: 2.049987\n",
            "[7,   100] loss: 2.033940\n",
            "[8,   100] loss: 2.020591\n",
            "[9,   100] loss: 2.007369\n",
            "[10,   100] loss: 1.995844\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 57.17 %\n",
            "[1,   100] loss: 1.983570\n",
            "[2,   100] loss: 1.973564\n",
            "[3,   100] loss: 1.964003\n",
            "[4,   100] loss: 1.957080\n",
            "[5,   100] loss: 1.950364\n",
            "[6,   100] loss: 1.943437\n",
            "[7,   100] loss: 1.938834\n",
            "[8,   100] loss: 1.931949\n",
            "[9,   100] loss: 1.927877\n",
            "[10,   100] loss: 1.923961\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 60.92 %\n",
            "[1,   100] loss: 1.919088\n",
            "[2,   100] loss: 1.915802\n",
            "[3,   100] loss: 1.911286\n",
            "[4,   100] loss: 1.908565\n",
            "[5,   100] loss: 1.905027\n",
            "[6,   100] loss: 1.902437\n",
            "[7,   100] loss: 1.899695\n",
            "[8,   100] loss: 1.896075\n",
            "[9,   100] loss: 1.894922\n",
            "[10,   100] loss: 1.890388\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 62.46 %\n",
            "[1,   100] loss: 1.888899\n",
            "[2,   100] loss: 1.887062\n",
            "[3,   100] loss: 1.884309\n",
            "[4,   100] loss: 1.882426\n",
            "[5,   100] loss: 1.881719\n",
            "[6,   100] loss: 1.879716\n",
            "[7,   100] loss: 1.876340\n",
            "[8,   100] loss: 1.873427\n",
            "[9,   100] loss: 1.872938\n",
            "[10,   100] loss: 1.873093\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 63.63 %\n",
            "[1,   100] loss: 1.869875\n",
            "[2,   100] loss: 1.868767\n",
            "[3,   100] loss: 1.867384\n",
            "[4,   100] loss: 1.865151\n",
            "[5,   100] loss: 1.864633\n",
            "[6,   100] loss: 1.861871\n",
            "[7,   100] loss: 1.860933\n",
            "[8,   100] loss: 1.859669\n",
            "[9,   100] loss: 1.857161\n",
            "[10,   100] loss: 1.856585\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 64.29 %\n",
            "[1,   100] loss: 1.855703\n",
            "[2,   100] loss: 1.854073\n",
            "[3,   100] loss: 1.852379\n",
            "[4,   100] loss: 1.851598\n",
            "[5,   100] loss: 1.850442\n",
            "[6,   100] loss: 1.849081\n",
            "[7,   100] loss: 1.848419\n",
            "[8,   100] loss: 1.846950\n",
            "[9,   100] loss: 1.847293\n",
            "[10,   100] loss: 1.845723\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 65.18 %\n",
            "[1,   100] loss: 1.844645\n",
            "[2,   100] loss: 1.843071\n",
            "[3,   100] loss: 1.841161\n",
            "[4,   100] loss: 1.840838\n",
            "[5,   100] loss: 1.841009\n",
            "[6,   100] loss: 1.839513\n",
            "[7,   100] loss: 1.838608\n",
            "[8,   100] loss: 1.837142\n",
            "[9,   100] loss: 1.836075\n",
            "[10,   100] loss: 1.834850\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 65.79 %\n",
            "[1,   100] loss: 1.833461\n",
            "[2,   100] loss: 1.835199\n",
            "[3,   100] loss: 1.832401\n",
            "[4,   100] loss: 1.832971\n",
            "[5,   100] loss: 1.830195\n",
            "[6,   100] loss: 1.830651\n",
            "[7,   100] loss: 1.830836\n",
            "[8,   100] loss: 1.828353\n",
            "[9,   100] loss: 1.829609\n",
            "[10,   100] loss: 1.826505\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 66.29 %\n",
            "[1,   100] loss: 1.826527\n",
            "[2,   100] loss: 1.826646\n",
            "[3,   100] loss: 1.825695\n",
            "[4,   100] loss: 1.825328\n",
            "[5,   100] loss: 1.823793\n",
            "[6,   100] loss: 1.824769\n",
            "[7,   100] loss: 1.823432\n",
            "[8,   100] loss: 1.822724\n",
            "[9,   100] loss: 1.820633\n",
            "[10,   100] loss: 1.821106\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 66.88 %\n",
            "[1,   100] loss: 1.820848\n",
            "[2,   100] loss: 1.820734\n",
            "[3,   100] loss: 1.818914\n",
            "[4,   100] loss: 1.819108\n",
            "[5,   100] loss: 1.817885\n",
            "[6,   100] loss: 1.816793\n",
            "[7,   100] loss: 1.817445\n",
            "[8,   100] loss: 1.816507\n",
            "[9,   100] loss: 1.815489\n",
            "[10,   100] loss: 1.816254\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 67.28 %\n",
            "[1,   100] loss: 1.814554\n",
            "[2,   100] loss: 1.813909\n",
            "[3,   100] loss: 1.814061\n",
            "[4,   100] loss: 1.812340\n",
            "[5,   100] loss: 1.812943\n",
            "[6,   100] loss: 1.811970\n",
            "[7,   100] loss: 1.813423\n",
            "[8,   100] loss: 1.811175\n",
            "[9,   100] loss: 1.810344\n",
            "[10,   100] loss: 1.811398\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 67.59 %\n",
            "[1,   100] loss: 1.809479\n",
            "[2,   100] loss: 1.809299\n",
            "[3,   100] loss: 1.809724\n",
            "[4,   100] loss: 1.809631\n",
            "[5,   100] loss: 1.810322\n",
            "[6,   100] loss: 1.807486\n",
            "[7,   100] loss: 1.806885\n",
            "[8,   100] loss: 1.806493\n",
            "[9,   100] loss: 1.807361\n",
            "[10,   100] loss: 1.805644\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 67.86 %\n",
            "[1,   100] loss: 1.806085\n",
            "[2,   100] loss: 1.805651\n",
            "[3,   100] loss: 1.804986\n",
            "[4,   100] loss: 1.804622\n",
            "[5,   100] loss: 1.804556\n",
            "[6,   100] loss: 1.804072\n",
            "[7,   100] loss: 1.804123\n",
            "[8,   100] loss: 1.803523\n",
            "[9,   100] loss: 1.803801\n",
            "[10,   100] loss: 1.802907\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 68.07 %\n",
            "[1,   100] loss: 1.801870\n",
            "[2,   100] loss: 1.802506\n",
            "[3,   100] loss: 1.802027\n",
            "[4,   100] loss: 1.800853\n",
            "[5,   100] loss: 1.800362\n",
            "[6,   100] loss: 1.800592\n",
            "[7,   100] loss: 1.800413\n",
            "[8,   100] loss: 1.800194\n",
            "[9,   100] loss: 1.801411\n",
            "[10,   100] loss: 1.799263\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 68.28 %\n",
            "[1,   100] loss: 1.799742\n",
            "[2,   100] loss: 1.799505\n",
            "[3,   100] loss: 1.798141\n",
            "[4,   100] loss: 1.798339\n",
            "[5,   100] loss: 1.797079\n",
            "[6,   100] loss: 1.797650\n",
            "[7,   100] loss: 1.796936\n",
            "[8,   100] loss: 1.797182\n",
            "[9,   100] loss: 1.796151\n",
            "[10,   100] loss: 1.795721\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 68.48 %\n",
            "[1,   100] loss: 1.795367\n",
            "[2,   100] loss: 1.796337\n",
            "[3,   100] loss: 1.795135\n",
            "[4,   100] loss: 1.795540\n",
            "[5,   100] loss: 1.795785\n",
            "[6,   100] loss: 1.795140\n",
            "[7,   100] loss: 1.794941\n",
            "[8,   100] loss: 1.795658\n",
            "[9,   100] loss: 1.793901\n",
            "[10,   100] loss: 1.794255\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 68.67 %\n",
            "[1,   100] loss: 1.793515\n",
            "[2,   100] loss: 1.793169\n",
            "[3,   100] loss: 1.792966\n",
            "[4,   100] loss: 1.792312\n",
            "[5,   100] loss: 1.790886\n",
            "[6,   100] loss: 1.793117\n",
            "[7,   100] loss: 1.790766\n",
            "[8,   100] loss: 1.791764\n",
            "[9,   100] loss: 1.791184\n",
            "[10,   100] loss: 1.792111\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 68.8 %\n",
            "[1,   100] loss: 1.790950\n",
            "[2,   100] loss: 1.791664\n",
            "[3,   100] loss: 1.790811\n",
            "[4,   100] loss: 1.790778\n",
            "[5,   100] loss: 1.789950\n",
            "[6,   100] loss: 1.789854\n",
            "[7,   100] loss: 1.790120\n",
            "[8,   100] loss: 1.789105\n",
            "[9,   100] loss: 1.789684\n",
            "[10,   100] loss: 1.790177\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 69.05 %\n",
            "[1,   100] loss: 1.788258\n",
            "[2,   100] loss: 1.788585\n",
            "[3,   100] loss: 1.788326\n",
            "[4,   100] loss: 1.788656\n",
            "[5,   100] loss: 1.787747\n",
            "[6,   100] loss: 1.788576\n",
            "[7,   100] loss: 1.787292\n",
            "[8,   100] loss: 1.787391\n",
            "[9,   100] loss: 1.788255\n",
            "[10,   100] loss: 1.787204\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 69.23 %\n",
            "[1,   100] loss: 1.786894\n",
            "[2,   100] loss: 1.787265\n",
            "[3,   100] loss: 1.785639\n",
            "[4,   100] loss: 1.787374\n",
            "[5,   100] loss: 1.784905\n",
            "[6,   100] loss: 1.784680\n",
            "[7,   100] loss: 1.785117\n",
            "[8,   100] loss: 1.785486\n",
            "[9,   100] loss: 1.785560\n",
            "[10,   100] loss: 1.784343\n",
            "Done training\n",
            "Accuracy of the network on the 10000 test images: 69.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6_kWgcgB9L1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5e08ea86-2d79-4a17-df05-c7bd3e846235"
      },
      "source": [
        "x_labels = [i*10 for i in range(len(accuracy_on_finetuning))]\n",
        "plt.plot(x_labels, accuracy_on_finetuning)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhc5Xn38e9t7ftiS7KRvBvjsNkY\nsQVCCFAClLJkJSsJeUPSZk/bBNItXa8sbdP07du0ZCUtKUlIAJckhIRCyPKGIIPxymKMHY+QZVn7\nvt794xyJsZFsydaZkeb8Ptc115xzNDPn1tHop0fPPOc55u6IiEh8LEh3ASIikloKfhGRmFHwi4jE\njIJfRCRmFPwiIjGTne4CpmPRokW+YsWKdJchIjKvbN68+ZC7Vx25fV4E/4oVK2hoaEh3GSIi84qZ\n7Ztsu7p6RERiJrLgN7NTzGxL0q3LzD5qZpVm9hMzey68r4iqBhERebnIgt/dn3H3De6+ATgb6APu\nAW4FHnL3k4GHwnUREUmRVHX1XAY87+77gOuAO8LtdwDXp6gGEREhdcF/I/Bf4XKNuzeFyweAmhTV\nICIipCD4zSwXuBb47pFf82CGuElniTOzW8yswcwaWlpaIq5SRCQ+UtHivwp4wt2bw/VmM1sCEN4f\nnOxJ7n67u9e7e31V1cuGoYqIyHFKxTj+t/BSNw/AJuAm4DPh/X0pqEFEZE4aHBmls2+Yzv5hOvqH\n6ewL7/uH6ewb4vVn17F8YdGs7jPS4DezIuB3gPclbf4M8B0zew+wD3hTlDWIiETN3ekfHqW9b5j2\n3iE6+4dp7xuivS8I787+YToOC/TxoB9iYHhsytc1g7OWV8yv4Hf3XmDhEdtaCUb5iIjMSaNjTmvP\nIM1dgzR3DXCoZ5COMMw7eoPAbu8bpqNvKAj0vmGGRqcO8IKcLMoLcygrCG7LFxZOrJcX5lJakEN5\nQc5L2wpyKSvIoSQ/mwULbNa/v3kxZYOIyGwYG3Nae4do7hrgYPcAB7vCcO8e4GDXwGFBPzbJsJPc\nrAWUF+ZQUZhLeWEOKxcVUVGYS1m4raIwh7KC4L58fL0wh7zsrNR/s0eh4BeReWFkdIyewZGJW+/g\nCD2Do/QMBMvd4bbk5Z6B8LFDI7T2DNHSPcjIJIm+sCiX6tJ8akrzOHVJKTWleVSX5lNdkkdNaT6L\nSvKoKMyhICcLs9lvgaeagl9EUm54dCzoA+8N+8J7g66T9r4h2nqHJra1hd0pbb1DdA+MTOu187IX\nUJKfTVFeNsV5wX11ST7rFgeBXlOaT3VJ/sTyouI8crPjNW2Zgl9EToi70zM4QlvvEK29QWC39gZh\nnXwb/1p77xDdg1OHeGFuFhWFuVQWBd0pKxYWTnStlObnUJyXTfFEsGdRnJdDUV4WJXk5FOZlkZMV\nrxA/Hgp+ETmMu9M9GHSNtPYM0to7dPhy7xBtvYO09Q7T1jtIe+/UH2zmZi9gYVEQ4pVFuRMhXlkU\n9H9XFOVSWZhLeVLQ5+fMrf7wTKTgF4mBvrCPOwjxwcOXe4c41DMYtMp7gtb5VEFekpdNZXEQ0rXl\n+ZxRW0pFUW4Y7nksLMpNWs+lMDcz+sQzjYJfZB4aGhmjtXfwqGGe3FrvHx6d9HUKcrJYWJzLwuKg\nv/vUJaUsLA4CfHz7+HJlUe6cG50ix0fBLzLH9A+NcqBrgKbOfg50DtDUOfDSfVew7VDP0KTPzc1a\nQGVSaK+uKg7X84JtRYeHeWGuIiCO9FMXSaHh0TGaOgZItPeRaO+fCPPkcO/sH37Z88oLc1hcms+S\nsnzOqC1ncWk+VSVBmC8qDrtZinMpyctW14ock4JfZBYdGewv3QfLB7oGXnZi0KLiPJaU5bO0spBz\nV1ZSEwb84rJ8lpQVsLg0n4JcdbHI7FHwi8xQ/9Aoz7f0sPtgD3taeo4a7AsMlpQVUFtRwPmrF1JX\nUUhdRUFwKy9kcVl+7MaQS/op+EWm0Nk3zO6WbnYfDEL+ufA+0d4/8ZijBfvSiiDYNa5c5hoFv8Sa\nu9PSM8ju5h52h63458Lllu7BicflZS9gVVUxG5dV8Kb6paypLubk6mKWLyxSi13mHQW/xMrYmPP0\ngW4e39vGb/a20bC3jeaulwK+JC+b1dXFvHptFSdXF7MmvNVVFJIVwSyJIumg4JeMNjgyyrZEJ7/Z\n28bjL7TRsK99Ys6XJWX5nLdyIRuWlrO2poQ11cXUlOZpVIxkPAW/ZJSewRE272vn8ReCFv1T+zsY\nHAnOQl1dVcQ1Zy7hnBWVnLOikrqKAoW8xJKCX+YtdyfR3s/WRCcN+9p4fG8bO1/sYswha4Fx2kml\nvP385WHQV7CwOC/dJYvMCQp+mRfcnRc7B9iW6GBropNtjcGtoy842SkvewFnLSvng69ZwzkrKzlr\nWQXFeXp7i0xGvxky57g7B7oG2JroZHtj50TQt/UG0xRkLzBOWVzClact5oy6Ms6sLeeUxSUaXSMy\nTQp+SbvO/mEa9rbxVFLQH+oJRtpkLTDW1pRw+SuqOaOunDNqy1i3uERT94qcAAW/pFx77xCPvdDG\nYy+08tieNnYd6MI9OBnq5OoSLjmlijPryji9toxTl5Qq5EVmmYJfItfSPchvkoL+meZuAPJzFrBx\nWQUfvWwt562q5My6Ms0WKZICkf6WmVk58BXgdMCBm4HXAu8FWsKHfcrdfxhlHZJazV0D/HpPa9Cq\n39PK8y29QHBJvbOXV3DthpM4b2UlZ9aVq19eJA2ibl59EXjA3d9gZrlAIUHwf8Hd/z7ifUuKjIyO\n8avnW/nhtiZ+vaeVva19ABTnZVO/ooI31i/lvJWVnF5bpnlrROaAyILfzMqAi4F3Abj7EDCkE2Yy\ng7uz48Uu7nmykU1PvUhL9yAledmct6qSt523nPNWVXLqklKyFfQic06ULf6VBN05Xzez9cBm4CPh\n1z5oZu8EGoA/dPf2I59sZrcAtwAsW7YswjJlJva39bHpqRe558lGdh/sISfLuHRdNTecVcslp1Tr\ng1iRecDc/diPOp4XNqsHfg1c6O6PmdkXgS7gX4BDBH3+fw0scfebj/Za9fX13tDQEEmdcmydfcP8\nYFsT9z7ZyG/2tgFw7opKrj+rlqvPWEx5YW6aKxSRyZjZZnevP3J7lC3+BJBw98fC9buBW929Oamo\nLwP3R1iDHKeB4VEeeeYg9zzZyMNPtzA0OsbqqiL++LWncO36k1haWZjuEkXkOEUW/O5+wMz2m9kp\n7v4McBmw08yWuHtT+LAbgO1R1SAzMzrmNOxt494tjfxgaxNdAyMsKs7jHRcs54azajntpFJNaiaS\nAaIe1fMh4M5wRM8e4N3AP5vZBoKunr3A+yKuQY5iX2svv9h9iF/uPsSvnm+lo2+YwtwsrjxtMdef\nVcsrVy/UB7QiGSbS4Hf3LcCR/UvviHKfcnRtvUP86vkg6H+x+xD724LLCC4py+fyV9Rw8doqLn9F\ntU6kEslg+u3OcAPDozy+t22iVb/jxWB6hJK8bM5fvZD3vmoVF65ZxKpFRerGEYkJBX+GGR1zdrzY\nyS92H+IXzx2iYV87QyNj5GQZG5dV8PHL13LhyYs4s7ZMXTgiMaXgzxADw6N8d3OC2x99fqL7Zt3i\nEt55/nIuPHkR566opEjz04sICv55r3tgmP/89W/56i9e4FDPIOuXlvOxy9dy0cmLqC7JT3d5IjIH\nKfjnqUM9g3z9ly/wzf+/j+6BES5as4g/uGQDF6xeqL56ETkqBf88k2jv48uP7uHbDfsZHBnjytMW\n8/uXrObMuvJ0lyYi84SCf554rrmbL/3seTZteRGAG86q5X2vXs2a6uI0VyYi842Cf47bsr+Df314\nNw/ubKYgJ4t3XLCc975qFSeVF6S7NBGZpxT8c5C788vdrfzrI7v51fOtlOZn8+FL1/CuC1dSWaQJ\n0UTkxCj455jtjZ38+X3beeK3HVSX5PGpq9fx1vOWU6yhmCIyS5Qmc0TP4Aj/+OCzfONXL1BZlMvf\n3nA6bzi7jrxszW8vIrNLwT8H/HjHAT69aQdNnQO89bxlfPK16ygrzEl3WSKSoRT8adTY0c9f3LeD\nn+5qZt3iEv7lrRs5e3lFussSkQyn4E+DkdExvv7LvXzhp8/iDrddtY6bL1qpC5GLSEoo+FNsy/4O\nPvX9bexs6uLSddX81XWnUVehq1mJSOoo+FOka2CYzz/wDP/52D6qS/L40ts2cuXpizW9goiknII/\nYu7O/Vub+Kv7d9LaM8hNF6zgD69YS0m+PrwVkfRQ8Efot619/Nl92/nZsy2cUVvG1246hzPqytJd\nlojEnII/Au7Ovz+6hy/85FlyshbwF793Ku+8YAVZC9StIyLpp+CPwF2P7+czP3qa155Ww19eezqL\nyzQvvojMHQr+WfZiRz9/+4NdvHL1Qv7t7Wfrw1sRmXM0cHwWuTu3fX8bY+589vVnKvRFZE6KNPjN\nrNzM7jazp81sl5ldYGaVZvYTM3suvM+YU1Xv3pzgZ8+28Mkr17G0UmPzRWRuirrF/0XgAXdfB6wH\ndgG3Ag+5+8nAQ+H6vNfcNcBf37+Tc1dW8o7zl6e7HBGRKUUW/GZWBlwMfBXA3YfcvQO4DrgjfNgd\nwPVR1ZAq7s6nvr+NodExPvf6M1mg0TsiModF2eJfCbQAXzezJ83sK2ZWBNS4e1P4mANAzWRPNrNb\nzKzBzBpaWloiLPPE3bulkYeePsgfXXEKKxYVpbscEZGjijL4s4GNwJfc/SyglyO6ddzdAZ/sye5+\nu7vXu3t9VVVVhGWemIPdA3x60042Livn3ReuTHc5IiLHFGXwJ4CEuz8Wrt9N8Ieg2cyWAIT3ByOs\nIVLuzp/du53+4VE+94b1OkFLROaFyILf3Q8A+83slHDTZcBOYBNwU7jtJuC+qGqI2v1bm/jxjmY+\n/jtrWVNdnO5yRESmJeoTuD4E3GlmucAe4N0Ef2y+Y2bvAfYBb4q4hki09gzyF5t2sL6ujP9zkbp4\nRGT+iDT43X0LUD/Jly6Lcr+p8OebdtAzMMLn37iebF1ARUTmESXWcXhgexM/2NrEhy9bw9qaknSX\nIyIyIwr+GWrvHeJP793OaSeV8r5Xr053OSIiM6ZJ2mboL/97Bx19w3zz5vN0jVwRmZeUXDPw053N\n3LvlRT546RpOPak03eWIiBwXBf80dfYN86l7trFucQl/cMmadJcjInLc1NUzTX/9g5209g7xtXed\nQ262/l6KyPylBJuGh585yN2bE/z+q1dzeq2umSsi85uC/xi6Boa57XvbWFtTzIcuUxePiMx/Cv5j\n+Lsf7OJg9wCff8N68rKz0l2OiMgJU/Afxc+fa+Gux/fz3otXsX5pebrLERGZFQr+KfQMjnDr97ax\nqqqIj12+Nt3liIjMGo3qmcKPtjXR2NHPXbecT36OunhEJHOoxT+F37b1scDg7OUZcy14ERFAwT+l\nRHs/S8oKNC2DiGQcpdoUGtv7qa0oSHcZIiKz7pjBb2YfMrPY9Xck2vuoK1fwi0jmmU6LvwZ43My+\nY2ZXmlnGX1h2aGSMA10D1KnFLyIZ6JjB7+5/CpwMfBV4F/Ccmf2dmWXsZPQHOgcYc6irKEx3KSIi\ns25affzu7sCB8DYCVAB3m9nnIqwtbRIdfQBq8YtIRjrmOH4z+wjwTuAQ8BXgj9192MwWAM8Bn4i2\nxNRLtPcDavGLSGaazglclcDr3H1f8kZ3HzOza6IpK70S7f2YweKy/HSXIiIy66bT1fMjoG18xcxK\nzew8AHffFVVh6ZRo72Nxab7m3ReRjDSdZPsS0JO03hNuOyYz22tm28xsi5k1hNs+bWaN4bYtZnb1\nzMuOVqK9X/37IpKxptPVY+GHu8BEF89M5vh5jbsfOmLbF9z972fwGinV2N7PuSsr012GiEgkptPi\n32NmHzaznPD2EWBP1IWly8ioxvCLSGabTvC/H3gl0AgkgPOAW6b5+g48aGabzSz5OR80s61m9rWp\nzgo2s1vMrMHMGlpaWqa5uxPX1DnA6JhTq7N2RSRDTecEroPufqO7V7t7jbu/1d0PTvP1L3L3jcBV\nwAfM7GKCzwdWAxuAJuAfptjv7e5e7+71VVVV09zdidNQThHJdNMZx58PvAc4DZgY3+juNx/rue7e\nGN4fNLN7gHPd/dGk1/4ycP9x1B2ZRLtO3hKRzDadrp7/ABYDrwV+BtQB3cd6kpkVmVnJ+DJwBbDd\nzJYkPewGYPtMi45SY0cwhn9Jucbwi0hmms7onDXu/kYzu87d7zCzbwE/n8bzaoB7wjndsoFvufsD\nZvYfZraBoP9/L/C+46w9Eon2fmpK8nVhdRHJWNMJ/uHwvsPMTieYr6f6WE9y9z3A+km2v2NGFaZY\nor1P8/CLSEabTlfP7eHImz8FNgE7gc9GWlUa6eQtEcl0R23xhxOxdbl7O/AosColVaXJyOgYTZ0a\nwy8ime2oLX53HyMDZ9+cSnP3IKNjrqGcIpLRptPV81Mz+yMzW2pmleO3yCtLg0SbhnKKSOabzoe7\nbw7vP5C0zcnAbp/xk7d01q6IZLJjBr+7r0xFIXPBePCfpOAXkQw2nTN33znZdnf/5uyXk16J9j6q\nS/LIz9EYfhHJXNPp6jknaTkfuAx4Asi44G/s0FBOEcl80+nq+VDyupmVA3dFVlEaJdr72bC0PN1l\niIhE6niuLdgLZFy//+iY82JHv87aFZGMN50+/v8mGMUDwR+KU4HvRFlUOjR3DTAy5urqEZGMN50+\n/uRLJI4A+9w9EVE9aaN5+EUkLqYT/L8Fmtx9AMDMCsxshbvvjbSyFGvs0MlbIhIP0+nj/y4wlrQ+\nGm7LKIk2nbwlIvEwneDPdveh8ZVwOTe6ktIj0d7PomKN4ReRzDed4G8xs2vHV8zsOuBQdCWlR6Kj\nT908IhIL0+njfz9wp5n9S7ieACY9m3c+a2zv5/TasnSXISISuemcwPU8cL6ZFYfrPZFXlWJjY05j\nRz9Xnr7k2A8WEZnnjtnVY2Z/Z2bl7t7j7j1mVmFmf5OK4lLlYPcgw6Mawy8i8TCdPv6r3L1jfCW8\nGtfV0ZWUeon2YCinztoVkTiYTvBnmVne+IqZFQB5R3n8vDN+8tZSBb+IxMB0Pty9E3jIzL4OGPAu\n4I7pvLiZ7QW6Ccb+j7h7fXj1rm8DK4C9wJvC/yLSprFjfAy/ztoVkcx3zBa/u38W+BvgFcApwI+B\n5TPYx2vcfYO714frtwIPufvJwEPhelol2vtYVJxLQa7G8ItI5pvu7JzNBBO1vRG4FNh1Avu8jpf+\nY7gDuP4EXmtWJNr7qdUcPSISE1N29ZjZWuAt4e0QQfeMuftrZvD6DjxoZg78u7vfDtS4e1P49QNA\nzRT7vwW4BWDZsmUz2OXMJdr7OXVJaaT7EBGZK47W4n+aoHV/jbtf5O7/l6CvfiYucveNwFXAB8zs\n4uQvurvz0pTPHPG129293t3rq6qqZrjb6RsbcxrbdeUtEYmPowX/64Am4GEz+7KZXUbw4e60uXtj\neH8QuAc4F2g2syUA4f3B4yl8thzqGWRodEzBLyKxMWXwu/u97n4jsA54GPgoUG1mXzKzK471wmZW\nZGYl48vAFcB2YBNwU/iwm4D7TuxbODH7NQ+/iMTMdKZs6AW+BXzLzCoIPuD9JPDgMZ5aA9xjZuP7\n+Za7P2BmjwPfMbP3APuAN51A/Sds/OQttfhFJC6mM45/Qjje/vbwdqzH7gHWT7K9FbhsJvuN0vjJ\nWzprV0Ti4ngutp5REu39VBblUpg7o7+BIiLzVuyDv7FDI3pEJF5iH/yJdl2ARUTiJdbB7z4+hl8j\nekQkPmId/C09gwyOjOkC6yISK7EO/sTEGH4Fv4jER6yDv1Enb4lIDMU6+DWGX0TiKObB30dFYQ7F\neRrDLyLxEfPg71drX0RiJ+bB30edLrcoIjET2+B3d521KyKxFNvgb+0dYmBY8/CLSPzENvgTGsop\nIjEV4+AP5uHXh7siEjexDf5GjeEXkZiKbfAn2vspK8ihND8n3aWIiKRUjINf0zGLSDzFOPj7NSun\niMRSLIPf3UloHn4RialYBn973zD9w6Pq6hGRWIpl8I8P5VTwi0gcRR78ZpZlZk+a2f3h+jfM7AUz\n2xLeNkRdw5F08paIxFkq5iP+CLALKE3a9sfufncK9j0pnbwlInEWaYvfzOqA3wW+EuV+ZirR3k9J\nfjZlBRrDLyLxE3VXzz8BnwDGjtj+t2a21cy+YGZ5kz3RzG4xswYza2hpaZnVoho1okdEYiyy4Dez\na4CD7r75iC/dBqwDzgEqgU9O9nx3v93d6929vqqqalZrC4ZyqptHROIpyhb/hcC1ZrYXuAu41Mz+\n092bPDAIfB04N8IaXiYYw6+zdkUkviILfne/zd3r3H0FcCPwP+7+djNbAmBmBlwPbI+qhsl09A3T\nOzSqs3ZFJLbScZXxO82sCjBgC/D+VO5cQzlFJO5SEvzu/gjwSLh8aSr2OZXGDp28JSLxFrszd8db\n/EvV4heRmIpl8JfkZVNakI5eLhGR9Ith8PdRW1FA8NmyiEj8xDD4NYZfROItVsHv7jprV0RiL1bB\n39U/QvfgiFr8IhJrsQr+/ZqHX0QkXsE/PpSztlxdPSISXzELfrX4RURiFfyNHf0U5WZRXqh5+EUk\nvmIV/IlwRI/G8ItInMUw+NXNIyLxFrPg79N1dkUk9mIT/J39w3QPaAy/iEhsgr9R8/CLiAAxCn4N\n5RQRCcQo+NXiFxGBmAV/QU4WFRrDLyIxF5vgb+zoo07z8IuIxCf4NYZfRCQQs+BX/76ISCyCv2tg\nmM7+YbX4RURIQfCbWZaZPWlm94frK83sMTPbbWbfNrPcqGsYH8Ovs3ZFRFLT4v8IsCtp/bPAF9x9\nDdAOvCfqAnTylojISyINfjOrA34X+Eq4bsClwN3hQ+4Aro+yBtDJWyIiyaJu8f8T8AlgLFxfCHS4\n+0i4ngBqJ3uimd1iZg1m1tDS0nJCRSTa+8nPWcDCosh7lURE5rzIgt/MrgEOuvvm43m+u9/u7vXu\nXl9VVXVCtWgefhGRl2RH+NoXAtea2dVAPlAKfBEoN7PssNVfBzRGWAMAiY4+asvVzSMiAhG2+N39\nNnevc/cVwI3A/7j724CHgTeED7sJuC+qGsY16uQtEZEJ6RjH/0ng42a2m6DP/6tR7qxncIT2vmGN\n6BERCUXZ1TPB3R8BHgmX9wDnpmK/kDyUUy1+ERGIwZm7GsopInK4GAS/ztoVEUmW8cHf2NFPXvYC\nqorz0l2KiMickPHBn2jvo1bz8IuITIhB8Gs6ZhGRZDEJfvXvi4iMy+jg7xsaoa13SGftiogkyejg\n1xh+EZGXy+jgT2gefhGRl8nw4A9O3lqqFr+IyIQMD/5+crMXsEhj+EVEJmR08K+qKuKGDbUsWKAx\n/CIi41IySVu6vPmcZbz5nGXpLkNEZE7J6Ba/iIi8nIJfRCRmFPwiIjGj4BcRiRkFv4hIzCj4RURi\nRsEvIhIzCn4RkZgxd093DcdkZi3AvuN8+iLg0CyWM1tU18yorplRXTMzV+uCE6ttubtXHblxXgT/\niTCzBnevT3cdR1JdM6O6ZkZ1zcxcrQuiqU1dPSIiMaPgFxGJmTgE/+3pLmAKqmtmVNfMqK6Zmat1\nQQS1ZXwfv4iIHC4OLX4REUmi4BcRiZmMDn4zu9LMnjGz3WZ2axrrWGpmD5vZTjPbYWYfCbd/2swa\nzWxLeLs6DbXtNbNt4f4bwm2VZvYTM3suvK9IcU2nJB2TLWbWZWYfTcfxMrOvmdlBM9uetG3S42OB\nfw7fb1vNbGOK6/q8mT0d7vseMysPt68ws/6k4/ZvKa5ryp+bmd0WHq9nzOy1Ka7r20k17TWzLeH2\nVB6vqbIh2veYu2fkDcgCngdWAbnAU8CpaaplCbAxXC4BngVOBT4N/FGaj9NeYNER2z4H3Bou3wp8\nNs0/xwPA8nQcL+BiYCOw/VjHB7ga+BFgwPnAYymu6wogO1z+bFJdK5Ifl4bjNenPLfwdeArIA1aG\nv69ZqarriK//A/DnaTheU2VDpO+xTG7xnwvsdvc97j4E3AVcl45C3L3J3Z8Il7uBXUBtOmqZpuuA\nO8LlO4Dr01jLZcDz7n68Z26fEHd/FGg7YvNUx+c64Jse+DVQbmZLUlWXuz/o7iPh6q+Buij2PdO6\njuI64C53H3T3F4DdBL+3Ka3LzAx4E/BfUez7aI6SDZG+xzI5+GuB/UnrCeZA2JrZCuAs4LFw0wfD\nf9m+luoulZADD5rZZjO7JdxW4+5N4fIBoCYNdY27kcN/IdN9vGDq4zOX3nM3E7QMx600syfN7Gdm\n9qo01DPZz22uHK9XAc3u/lzStpQfryOyIdL3WCYH/5xjZsXA94CPunsX8CVgNbABaCL4dzPVLnL3\njcBVwAfM7OLkL3rw/2VaxvyaWS5wLfDdcNNcOF6HSefxmYqZ/QkwAtwZbmoClrn7WcDHgW+ZWWkK\nS5pzP7cjvIXDGxcpP16TZMOEKN5jmRz8jcDSpPW6cFtamFkOwQ/2Tnf/PoC7N7v7qLuPAV8mon9z\nj8bdG8P7g8A9YQ3N4/8+hvcHU11X6CrgCXdvDmtM+/EKTXV80v6eM7N3AdcAbwsDg7ArpTVc3kzQ\nl742VTUd5ec2F45XNvA64Nvj21J9vCbLBiJ+j2Vy8D8OnGxmK8OW443ApnQUEvYhfhXY5e7/mLQ9\nuW/uBmD7kc+NuK4iMysZXyb4cHA7wXG6KXzYTcB9qawryWEtsXQfryRTHZ9NwDvDkRfnA51J/65H\nzsyuBD4BXOvufUnbq8wsK1xeBZwM7ElhXVP93DYBN5pZnpmtDOv6TarqCl0OPO3uifENqTxeU2UD\nUb/HUvHJdbpuBJ+AP0vwF/tP0ljHRQT/qm0FtoS3q4H/ALaF2zcBS1Jc1yqCURVPATvGjxGwEHgI\neA74KVCZhmNWBLQCZUnbUn68CP7wNAHDBP2p75nq+BCMtPh/4fttG1Cf4rp2E/T/jr/H/i187OvD\nn+8W4Ang91Jc15Q/N+BPwuP1DHBVKusKt38DeP8Rj03l8ZoqGyJ9j2nKBhGRmMnkrh4REZmEgl9E\nJGYU/CIiMaPgFxGJGQW/iJny7UgAAAJASURBVEjMKPglFsysJ7xfYWZvneXX/tQR67+azdcXmW0K\nfombFcCMgj88u/NoDgt+d3/lDGsSSSkFv8TNZ4BXhfOsf8zMsiyYx/7xcBKx9wGY2SVm9nMz2wTs\nDLfdG05mt2N8Qjsz+wxQEL7eneG28f8uLHzt7RZc8+DNSa/9iJndbcH8+XeGZ3BiZp+xYG72rWb2\n9yk/OhILx2rJiGSaWwnmhr8GIAzwTnc/x8zygF+a2YPhYzcCp3swZTDAze7eZmYFwONm9j13v9XM\nPujuGybZ1+sIJiZbDywKn/No+LWzgNOAF4FfAhea2S6CKQ3WubtbeCEVkdmmFr/E3RUEc59sIZgO\ndyHB3CwAv0kKfYAPm9lTBHPdL0163FQuAv7LgwnKmoGfAeckvXbCg4nLthB0QXUCA8BXzex1QN8k\nrylywhT8EncGfMjdN4S3le4+3uLvnXiQ2SUEE3pd4O7rgSeB/BPY72DS8ijBlbNGCGauvJtghs0H\nTuD1Raak4Je46Sa4xN24HwO/H06Ni5mtDWcqPVIZ0O7ufWa2juCyd+OGx59/hJ8Dbw4/R6giuPzf\nlLNPhnOyl7n7D4GPEXQRicw69fFL3GwFRsMum28AXyToZnki/IC1hckvNfkA8P6wH/4Zgu6ecbcD\nW83sCXd/W9L2e4ALCGY/deAT7n4g/MMxmRLgPjPLJ/hP5OPH9y2KHJ1m5xQRiRl19YiIxIyCX0Qk\nZhT8IiIxo+AXEYkZBb+ISMwo+EVEYkbBLyISM/8LHeaNtgc/ug0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7EyPMyg75Sh",
        "colab_type": "text"
      },
      "source": [
        "We can see in the above graph that, the network comppression works as expected and converges around 70% accuracy after 200 epochs using Adam optimizer"
      ]
    }
  ]
}